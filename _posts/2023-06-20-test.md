---
layout: post
title:  "test"
date:   2023-06-20
---

This blog post is not intended as an introduction to WebGPU. I, like you, am, at the time of writing, a GPU neophyte. Instead, I am going to demonstrate one solution to a specific problem. And I’ll do that by walking though the code for a simple in-browser drawing application written using WebGPU. In the process I’ll explain just enough of the concepts involved to make the code intelligible to the reader. I’ll also provide links to more thorough explanations.

The drawing application is just a simplified version of [Your first WebGPU app](https://codelabs.developers.google.com/your-first-webgpu-app#0) to which I’ve added user input. 


Here it is. Draw to your heart's content:

<div style ="
    display: flex;
    width: 100%;
    justify-content: center;
    padding: 1rem 0 1rem 0"
>
<iframe src="https://averyburke.github.io/GPUameOfLife/" width = "400" height = "400"></iframe>
</div>

I assume several hours have passed. Get a drink of water and assure your children that you still love them, even though you're going to spend most of your time at the computer from now on, drawing.

Our problem then, is this: *how do we get user inpute into a WebGPU program, running on the GPU?*

# Overview

Conceptually, the canvas is divided into an N X N grid of squares. We’ll store an N * N array of 1s and 0s to keep track of the state of each cell. A 1 at index n in the grid state array means the n<sup>th</sup> cell is active, and should be colored in, and a 0 means that cell is inactive. We’ll also store an N * N array of 1s and 0s to keep track of the user input. A 1 at index n in the input array means the user has selected the n<sup>th</sup> cell. Whenever the user selects a cell we’ll update the grid state, draw a new grid and then clear the input array for the next update.

Of course, the situation more complicated than that because for some reason we’ve chosen to implement this app using WebGPU. 

WebGPU is an API for executing code on the GPU. It interacts with your OS's native graphics API through an abstraction called an [adapter](https://www.w3.org/TR/webgpu/#adapter). And WebGPU exposes the GPU to you though another abstraaction called a [logical device](https://www.w3.org/TR/webgpu/#devices). To access an adapter you call `navigator.gpu.requestAdapter()` and you request a device from an `adapter` using the `adapter.requestDevice()` method. WebGPU is asynchronous and an adapter and device must be awaited.
{% highlight typescript %}
async function main() {
  const adapter = await navigator.gpu?.requestAdapter();
  const device = await adapter?.requestDevice();
  /* all the good stuff goes here */
}
main();
{% endhighlight %}

You request GPU objects from the device and submit commands to the device’s queue. Sending code from the CPU to the GPU takes time. A lot of WebGPU application code therefor ends up being preliminary table setting for *pipelines* which process and run code on the GPU. Data must be copied from JavaScript [typed arrays](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray) into different [GPU buffers](https://www.w3.org/TR/webgpu/#buffers). Buffers have to be bound to variables in the code that the pipelines will run, then a pipeline needs to configued to run that code with those buffer associations.

WebGPU can draw triangles, points or lines and it can perform large groups of computations in parallel. And GPUs are very good a linear algebra, if you’re into that sort of thing. The code for drawing and the code for doing computations are run in *pipelines* which feed data from the buffers to programs that run on the GPU called *shaders*. The data is exposed to the shaders through variables called *attributes*.

Sending code from the CPU to the GPU takes time. A lot of WebGPU application code therefor ends up being preliminary table setting so that shaders can be run with only a few commands from the CPU. 



# Pipelines and shaders

According the [W3C working draft for WebGPU](https://www.w3.org/TR/webgpu/#intro)
>GPUs execute commands encoded in GPUCommandBuffers by feeding data through a pipeline, which is a mix of fixed-function and programmable stages. Programmable stages execute *shaders*, which are special programs designed to run on GPU hardware. Most of the state of a pipeline is defined by a GPURenderPipeline or a GPUComputePipeline object.

I'll get to GPUCommandBuffers below. But first pipelines and shaders. A GPURenderPipeline object and a GPUComputePipeline object expose the aformentioned programmable stages of a *render pipline* and a *compute pipeline*, respectivly. The shader programs are written in a rust-like language called [WGSL](https://google.github.io/tour-of-wgsl/).

A render pipeline handles rasterization and coloring. For the purposes of this post "rasterization" is just the processes of drawing triangles on screen. There are two programable stages in the render pipeline&mdash;*the vertex shader* and the *fragment shader*. The vertex shader is invoked once per vertex. The render pipeline feeds vertices to the vertex shader as vectors. Transforms and other processes can be applied to vectors in a vertex shader. For every group of three vectors the vertex shader draws the triangle that connects them. A vertex shade can also optionally output values that get interpolated between the vertices of the triangle. These values are passed to the fragment shader as [inter-stage variables](https://webgpufundamentals.org/webgpu/lessons/webgpu-inter-stage-variables.html).

A fragment shader is invoked once pre pixel, for each triangle. It outputs colors. It can output to the canvas or to a memory backed GPU resource called a [frame buffer](something#). Our app outputs to the canvas. Back in the 80s when the town barber was also the town surgeon every shader was a fragment shader. That is, all that GPU code did was color pixles. This is where shaders get there somewhat confusing name&mdash;they just provided shading.

The compute pipeline is one of the features that recommends WebGPU over its predecessor WebGL. GPUs are designed for graphics processing. As such they are built to optimize throughput, they can preform fast matrix math and they have many more cores than a CPU. The compute pipeline allows developers to write *compute shaders* that can take advantage of the parallel processing abilities of GPUs. Using GPUs for compute (rather than for graphics) is referred to as “general purpose GPU” or “GPGPU.” GPGPU (have you ever said a phrase so many times that it starts to loose meaning?) can be used for dramatic performance gains in compute time.

The real feature that sets a compute shader apart from a vertex shader or a fragment shader is just that it outputs general numeric data to a buffer that other pipelines and other shaders can use. Whereas vertex shaders can only rasterize and output inter-stage variables, for fragment shaders, and fragment shaders can only output data as colors.  If you want to use vertex shaders and fragment shaders for GPGU you have to encode the resultss of your computations as colors, then write those colors to a frame buffer, then decode the colors in the next vertex shader.

Our app is going to compute the state of the grid in a compute shader, which will output the result to abuffer. Then the render pipeline will make the results buffer available to the vertex shader, which will display each cell depending on its state in the result buffer. Each cell of the grid will be made of two traingles. Those triangles will be colord in by a fragment shader.

**mention ping pong here**

# The compute shader

*What decides the state of each cell?* 

It is some combination of the current state of the cell (active or inactive) and whether the user selected the cell. If the cell was selected, then we want its state to change. That is, if the cell’s index in the input array is a 1 then the user selected it and we want the compute shader to change the cell’s state (from a 0 to a 1, or from a 1 to a 0). And if the cell’s index in the input array is a 0, then we want the current state to pass through the compute pipeline unchanged.

in other words we want the follow behavior:
<div style ="
    display: flex;
    width: 100%;
    justify-content: center;
    padding: 1rem 0 1rem 0
    "
>
<table style="
    width: 250px;
">
  <thead>
    <tr>
      <th style="text-align: center">input state</th>
      <th style="text-align: center">cell state in</th>
      <th style="text-align: center">cell state out</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center">1</td>
      <td style="text-align: center">1</td>
      <td style="text-align: center">0</td>
    </tr>
    <tr>
      <td style="text-align: center">1</td>
      <td style="text-align: center">0</td>
      <td style="text-align: center">1</td>
    </tr>
    <tr>
      <td style="text-align: center">0</td>
      <td style="text-align: center">1</td>
      <td style="text-align: center">1</td>
    </tr>
    <tr>
      <td style="text-align: center">0</td>
      <td style="text-align: center">0</td>
      <td style="text-align: center">0</td>
    </tr>
  </tbody>
</table>
</div>
And this is just the truth table of the "exclusive or" [\[xor\]](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Operators/Bitwise_XOR) operator. So the compute shader can find the current state of the cell, and the current state of the input array, from the cell's index, and then write the xor of those two states to the output buffer.

Our compute shader will use a [builtin variable](https://gpuweb.github.io/gpuweb/wgsl/#builtin-inputs-outputs) called `global_invocation_id` to index into the grid state array and the input state array. The GPU supplies the builtin variable with a value.  From [Your First WebGPU App](https://codelabs.developers.google.com/your-first-webgpu-app#7):

>You pass in the global_invocation_id builtin, which is a three-dimensional vector of unsigned integers that tells you where in the grid of shader invocations you are. You run this shader once for each cell in your grid. You get numbers like (0, 0, 0), (1, 0, 0), (1, 1, 0)... all the way to (31, 31, 0), which means that you can treat it as the cell index you're going to operate on!

*What is the grid of shader invocations and why is `global_invocation_id` a 3D vector?* 

This has to do with how the GPU executes computations in parallel.  A GPU has many more cores than a CPU, but the GPU’s cores do not operate independantly. They're grouped. Each group of cores work from the same memory cache and execute commands in lockstep. Furthermore, while a vertex shader is invoked once per vertices and a fragment shader is invoked once per pixel, a compute shader is invoked once pre *work item*.  From [WebGPU — All of the cores, none of the canvas](https://surma.dev/things/webgpu/):

>The collection of all work items (which I will call the “workload”) is broken down into workgroups. All work items in a workgroup are scheduled to run together. In WebGPU, the work load is modelled as a 3-dimensional grid, where each “cube” is a work item, and work items are grouped into bigger cuboids to form a **workgroup.**

*why is the "workload" modled as a 3D grid?"

I have no idea.

The size of the workgroup has to be specified in the compute shader using the `@workgroup_size(x, y, z)` attribute. This attribute specifies the size of the cuboids of work items to be executed together. Then the grid of shader invocations is the 3D grid mentioned above and `global_invocation_id` is the coordinate of the shader invocation in that grid. 

A compute shader is declared by using the `@compute` attribute and our workgroup size is going to be 64. Bcause [for some reason 64 is best](64_is_best#).

{% highlight rust %}
@compute @workgroup_size(8, 8) // a missing parameter is treated as a 1. So this is a work group of size 64 (8 X 8 X 1)
fn computeMain(@builtin(global_invocation_id) cell: vec3u){
    let i = cellIndex(cell.xy);

    /* cellStateOut = inputState[i] xor cellState[i] */
    cellStateOut[i] = inputState[i] ^ cellStateIn[i];
        
}
{% endhighlight %}

We also have a helper function to get the cell index from the x and y coordinates of the current shader invocation.

{% highlight rust %}
/* find the cell index */
fn cellIndex(cell: vec2u) -> u32 {
    return (cell.y % u32(grid.y)) * u32(grid.x) +
        (cell.x % u32(grid.x));
    }

fn cellActive(x: u32, y: u32) -> u32 {
    return cellStateIn[cellIndex(vec2(x, y))];
    }
{% endhighlight %}

Finally, the compute pipline makes the buffers available to the compute shader through *bind groups*. 

{% highlight rust %}
@group(0) @binding(0) var<uniform> grid: vec2f;
@group(0) @binding(1) var<storage, read> inputState: array<u32>;
@group(0) @binding(2) var<storage> cellStateIn: array<u32>;
@group(0) @binding(3) var<storage, read_write> cellStateOut: array<u32>;
{% endhighlight %}

# Resource Layouts

Declaring layouts is part of the table setting I mentioned above. Layouts describe the structure, type and purpose of the GPU resources that will be used by a pipeline. We need a `GPUBindGroupLayout` to describe our *bind group* and we'll need a `GPUPipelineLayout` to describe which `GPUBindGroupLayout`s the pipeline will use. 

The bind group layout describes bindings in within a bind group. A bind group is how resources are exposed to shaders. 

{% highlight typescript %}
const bindGroupLayout = device.createBindGroupLayout({ // request a bind group from the device, with the following configuration
        label: "Bind Group Layout",
        entries: [{
            binding: 0,
            visibility: GPUShaderStage.VERTEX | GPUShaderStage.COMPUTE | GPUShaderStage.FRAGMENT, // exposed during all 3 stages
            buffer: {} // Grid uniform buffer
        },{
            binding: 1,
            visibility: GPUShaderStage.COMPUTE, // exposed to the compute shader only
            buffer: { type: "read-only-storage" } // Cell selected input buffer, from user data
        },{
            binding: 2,
            visibility: GPUShaderStage.VERTEX | GPUShaderStage.COMPUTE, // exposed to the vertex shader and the compute shader
            buffer: { type: "read-only-storage" } // Cell state input buffer
        },{
            binding: 3,
            visibility: GPUShaderStage.COMPUTE, // exposed to the compute shader only
            buffer: { type: "storage" } // Cell state output buffer
        }]
    });
{% endhighlight %}

You will see and advantage of 

Bind group layouts are passed to pipelines through `GPUPipelineLayout`.

{% highlight typescript %}
const pipelineLayout = device.createPipelineLayout({ // request a pipeline layout with the following configuration
    label: "Pipeline Layout",// give it a really creative name, like "pipeline layout"
    bindGroupLayouts: [bindGroupLayout], // you can pass an array of bind group layouts, but we only have one
});
{% endhighlight %}

This bind group layout only describes the bindgroup. 

The bind group for the compute shader is declared like this:

{% highlight typescript %}
device.createBindGroup({
    label: "Render bind group A",
    layout: bindGroupLayout,
        entries: [
            {
                binding: 0,
                resource: { buffer: uniformBuffer }
            },
            {
                binding: 1,
                resource: { buffer: cellStateStorage[0] }
            },
            {
                binding: 2,
                resource: { buffer: cellStateStorage[1] }
            },
            {
                binding: 3,
                resource: { buffer: cellStateStorage[2] }
            }
        ],
})
{% endhighlight %}

Each resource is given a binding point and assigned a buffer from which the data is copied. We're keeping the vertex buffers in an array called `cellStateStorage` to make it easier to swap buffers between `cellStateIn` and `cellStateOut` on every grid update. But to swap buffers we really need two bind groups.

{% highlight typescript %}
  const bindGroups = [
        device.createBindGroup({
            label: "Render bind group A",
            layout: bindGroupLayout,
            entries: [
                {
                    binding: 0,
                    resource: { buffer: uniformBuffer }
                },
                {
                    binding: 1,
                    resource: { buffer: cellStateStorage[0] }
                },
                {
                    binding: 2,
                    resource: { buffer: cellStateStorage[1] }
                },
                {
                    binding: 3,
                    resource: { buffer: cellStateStorage[2] }
                }
            ],
        }),
        device.createBindGroup({
            label: "Render bind group B",
            layout: bindGroupLayout,
            entries: [
                {
                    binding: 0,
                    resource: { buffer: uniformBuffer }
                },
                {
                    binding: 1,
                    resource: { buffer: cellStateStorage[0] }
                },
                {
                    binding: 2,
                    resource: { buffer: cellStateStorage[2] }
                },
                {
                    binding: 3,
                    resource: { buffer: cellStateStorage[1] }
                }

            ],
        })
    ];
{% endhighlight %}

Notice that binding's 2 and 3 have swiched buffers between "Render bind group A" and "Render bind group B." 

Buffers have to be declared with a size and a usage. 

{% highlight typescript %}
  // Create an array representing the active state of each cell.
  const cellStateArray = new Uint32Array(gridWidth * gridHeight); // one 32 bit interger per cell

  // Create a storage buffer to hold the cell state.
  const cellStateStorage = [
      device.createBuffer({
          label: "Cell State A",
          size: cellStateArray.byteLength, // length of the cellStateArray
          usage: GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_DST // read and write
      }),
      device.createBuffer({
          label: "Cell State B",
          size: cellStateArray.byteLength, // length of the cellStateArray
          usage: GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_DST // read and write
      }),
      device.createBuffer({
          label: 'Cell State Input Buffer',
          size: cellStateArray.byteLength, // length of the cellStateArray
          usage: GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_DST // read and write
      })
  ];
{% endhighlight %}

these calls reserve buffers on the GPU into which we will copy data.

And the gird width and height are stored in an array as two float 32s 

{% highlight typescript %}
  const uniformArray = new Float32Array([gridWidth, gridHeight])
  const uniformBuffer = device.createBuffer({
      label: "Grid Uniforms",
      size: uniformArray.byteLength,
      usage: GPUBufferUsage.UNIFORM | GPUBufferUsage.COPY_DST,
  });
{% endhighlight %}


Then the full code for the compute shader looks like this:


{% highlight typescript %}

 const  computeShaderModule = device.createShaderModule({
    label: "Compute Shader",
    code: `
    @group(0) @binding(0) var<uniform> grid: vec2f;
    @group(0) @binding(1) var<storage, read> inputState: array<u32>;
    @group(0) @binding(2) var<storage> cellStateIn: array<u32>;
    @group(0) @binding(3) var<storage, read_write> cellStateOut: array<u32>;

    /* find the cell index */
    fn cellIndex(cell: vec2u) -> u32 {
        return (cell.y % u32(grid.y)) * u32(grid.x) +
               (cell.x % u32(grid.x));
      }
    
    fn cellActive(x: u32, y: u32) -> u32 {
        return cellStateIn[cellIndex(vec2(x, y))];
      }

    @compute @workgroup_size(8, 8) // a missing parameter is treated as a 1. So this is a work group of size 64 (8 X 8 X 1)
    fn computeMain(@builtin(global_invocation_id) cell: vec3u){
        let i = cellIndex(cell.xy);

        /* cellStateOut[i] = inputState[i] xor cellState[i] */
        cellStateOut[i] = inputState[i] ^ cellStateIn[i];
            
    }
    `
})
{% endhighlight %}


A compute pipeline unsurprisingly handles compute. The only programmable stages is called "compute." We’ll request a GPUComputePipeline object from the device and pass the grid state array and the input array to our compute shader, through our compute pipeline. 

{% highlight typescript %}
const computePipeline = device.createComputePipeline({// request the compute pipline from the device
    label: "Compute pipeline", // give the compute pipline a creative name like "compute pipeline"
    layout: pipelineLayout, // this is how the compute pipeline will associate buffers to attributes in the shader. More on this below
    compute: {device.createBindGroup(
        module: computeShaderModule, // the code for the compute shader
        entryPoint: "computeMain", // main function of the compute shader
    )}
});
{% endhighlight %}



Our compute shader will decided the state of each cell, but ... in parellel! The resulting new state will be written into a buffer for use by the render pipeline. 

The render pipeline handles rasterization and drawing. We'll request a GPURenderPipeline object from the device. There are two programable stages that we will use in the render pipeline. These are *the vertex shader* and the *fragment shader.* The vertex shader is invoked once per vertex. The render pipeline feeds vertices to the vertex shader as vectors. For every group of three vectors the vertex shader draws the triangle that connects them. It can also optionally output values that get interpolated between the vertices of the triangle. These values are passed to the fragment shader as [inter-stage variables](https://webgpufundamentals.org/webgpu/lessons/webgpu-inter-stage-variables.html).

The fragment shader is invoked once pre pixel, for each triangle. It outputs colors.

Fragment shaders can output to the canvas or to memory backed phyisical resources on the GPU called [textrues](https://webgpufundamentals.org/webgpu/lessons/webgpu-textures.html). Ours will render to the canvas. 

{% highlight typescript %}
 const renderPipeline = device.createRenderPipeline({
        label: "Render pipeline", //let your imagination run wild with these names
        layout: pipelineLayout,
        vertex: {
            module: renderShadersModule,//the code for the two shaders
            entryPoint: "vertexMain",
            buffers: [vertexBufferLayout] //this tells the the pipline how to feed verticies to the vertex shader and from which buffers. More on this below.
        },
        fragment: {
            module: renderShadersModule,//the code for the two shaders
            entryPoint: "fragmentMain",
            targets: [{
                format: canvasFormat //this tells the fragment shader to draw to the canvas. More on this below.
            }]
        }
    });
{% endhighlight %}

The big difference between a compute shader and the other shaders I've mentioned is that the compute shader outputs to a buffer that can be accessed directly by another pipline or by the CPU through [buffer mapping](https://www.w3.org/TR/webgpu/#buffer-mapping).



# The Compute Pipeline, Bind Groups and Buffers

The `@group(0)` and `@binding(...)` declaractions specifie bindings within a bind group. In this example all the bindings are part of one bind group: `@group(0)`.

In order to associate buffers with the bindings in a bind group the application code has to define a `GPUBindGroupLayout` which declares entry points for each binding, declares at which stage the binding is exposed and declares how the GPU should use the associated buffer. Here's the bind group layout for the app:

{% highlight typescript %}
const bindGroupLayout = device.createBindGroupLayout({ // request a bind group from the device, with the following configuration
        label: "Bind Group Layout",
        entries: [{
            binding: 0,
            visibility: GPUShaderStage.VERTEX | GPUShaderStage.COMPUTE | GPUShaderStage.FRAGMENT, // exposed during all 3 stages
            buffer: {} // Grid uniform buffer
        },{
            binding: 1,
            visibility: GPUShaderStage.COMPUTE, // exposed to the compute shader only
            buffer: { type: "read-only-storage" } // Cell selected input buffer, from user data
        },{
            binding: 2,
            visibility: GPUShaderStage.VERTEX | GPUShaderStage.COMPUTE, // exposed to the vertex shader and the compute shader
            buffer: { type: "read-only-storage" } // Cell state input buffer
        },{
            binding: 3,
            visibility: GPUShaderStage.COMPUTE, // exposed to the compute shader only
            buffer: { type: "storage" } // Cell state output buffer
        }]
    });
{% endhighlight %}

The bind group layout is passed to the piplines through a `GPUPiplineLayout`.

{% highlight typescript %}
const pipelineLayout = device.createPipelineLayout({ // request a pipeline layout with the following configuration
    label: "Pipeline Layout",
    bindGroupLayouts: [bindGroupLayout], // you can pass an array of bind group layouts, but we only have one
});

Then the compute pipeline looks like this:
 const computePipeline = device.createComputePipeline({
        label: "Compute pipeline",
        layout: pipelineLayout,
        compute: {
            module: computeShaderModule,
            entryPoint: "computeMain",
        }
    });
{% endhighlight %}

The bind group for the compute shader is declared like this:

{% highlight typescript %}
device.createBindGroup({
    label: "Render bind group A",
    layout: bindGroupLayout,
        entries: [
            {
                binding: 0,
                resource: { buffer: uniformBuffer }
            },
            {
                binding: 1,
                resource: { buffer: cellStateStorage[0] }
            },
            {
                binding: 2,
                resource: { buffer: cellStateStorage[1] }
            },
            {
                binding: 3,
                resource: { buffer: cellStateStorage[2] }
            }
        ],
})
{% endhighlight %}

Each resource is given a binding point and assigned a buffer from which the data is copied. We're keeping the vertex buffers in an array called `cellStateStorage` to make it easier to swap buffers between `cellStateIn` and `cellStateOut` on every grid update. But to swap buffers we really need two bind groups.

{% highlight typescript %}
  const bindGroups = [
        device.createBindGroup({
            label: "Render bind group A",
            layout: bindGroupLayout,
            entries: [
                {
                    binding: 0,
                    resource: { buffer: uniformBuffer }
                },
                {
                    binding: 1,
                    resource: { buffer: cellStateStorage[0] }
                },
                {
                    binding: 2,
                    resource: { buffer: cellStateStorage[1] }
                },
                {
                    binding: 3,
                    resource: { buffer: cellStateStorage[2] }
                }
            ],
        }),
        device.createBindGroup({
            label: "Render bind group B",
            layout: bindGroupLayout,
            entries: [
                {
                    binding: 0,
                    resource: { buffer: uniformBuffer }
                },
                {
                    binding: 1,
                    resource: { buffer: cellStateStorage[0] }
                },
                {
                    binding: 2,
                    resource: { buffer: cellStateStorage[2] }
                },
                {
                    binding: 3,
                    resource: { buffer: cellStateStorage[1] }
                }

            ],
        })
    ];
{% endhighlight %}

Notice that binding's 2 and 3 have swiched buffers between "Render bind group A" and "Render bind group B." 

Buffers have to be declared with a size and a usage. 

{% highlight typescript %}
  // Create an array representing the active state of each cell.
  const cellStateArray = new Uint32Array(gridWidth * gridHeight); // one 32 bit interger per cell

  // Create a storage buffer to hold the cell state.
  const cellStateStorage = [
      device.createBuffer({
          label: "Cell State A",
          size: cellStateArray.byteLength, // length of the cellStateArray
          usage: GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_DST // read and write
      }),
      device.createBuffer({
          label: "Cell State B",
          size: cellStateArray.byteLength, // length of the cellStateArray
          usage: GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_DST // read and write
      }),
      device.createBuffer({
          label: 'Cell State Input Buffer',
          size: cellStateArray.byteLength, // length of the cellStateArray
          usage: GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_DST // read and write
      })
  ];
{% endhighlight %}

these calls reserve buffers on the GPU into which we will copy data.

And the gird width and height are stored in an array as two float 32s 

{% highlight typescript %}
  const uniformArray = new Float32Array([gridWidth, gridHeight])
  const uniformBuffer = device.createBuffer({
      label: "Grid Uniforms",
      size: uniformArray.byteLength,
      usage: GPUBufferUsage.UNIFORM | GPUBufferUsage.COPY_DST,
  });
{% endhighlight %}


Then the full code for the compute shader looks like this:


{% highlight typescript %}

 const  computeShaderModule = device.createShaderModule({
    label: "Compute Shader",
    code: `
    @group(0) @binding(0) var<uniform> grid: vec2f;
    @group(0) @binding(1) var<storage, read> inputState: array<u32>;
    @group(0) @binding(2) var<storage> cellStateIn: array<u32>;
    @group(0) @binding(3) var<storage, read_write> cellStateOut: array<u32>;

    /* find the cell index */
    fn cellIndex(cell: vec2u) -> u32 {
        return (cell.y % u32(grid.y)) * u32(grid.x) +
               (cell.x % u32(grid.x));
      }
    
    fn cellActive(x: u32, y: u32) -> u32 {
        return cellStateIn[cellIndex(vec2(x, y))];
      }

    @compute @workgroup_size(8, 8) // a missing parameter is treated as a 1. So this is a work group of size 64 (8 X 8 X 1)
    fn computeMain(@builtin(global_invocation_id) cell: vec3u){
        let i = cellIndex(cell.xy);

        /* cellStateOut[i] = inputState[i] xor cellState[i] */
        cellStateOut[i] = inputState[i] ^ cellStateIn[i];
            
    }
    `
})
{% endhighlight %}

FInally, data needs to be coppied into the buffers with using `queue.writeBuffer()`.

{% highlight typescript %}
  device.queue.writeBuffer(uniformBuffer, 0, uniformArray); // copy the uniform buffer to the GP
  device.queue.writeBuffer(cellStateStorage[0], 0, cellStateArray); // copy the buffer associated to "Cell State A" to the GPU
  device.queue.writeBuffer(cellStateStorage[2], 0, cellStateArray); // copy the the input state to the GPU
{% endhighlight %}

After these calls we can reuse the buffer objects we got from the device, if we want, without having to worry about currupting the data that the shader is using, since it has been copied into the GPU buffers.

All this comes together in the compute pass of our `updateGrid()` function. Where a *command buffer* is created and submitted to the WebGPU. 

# Command Buffers, The Compute Pass and UpdateGrid()

Pipelines are initilized using command buffers. From [WebGPU Fundamentals](https://webgpufundamentals.org/webgpu/lessons/webgpu-fundamentals.html):

> Command buffers ... are a buffer of commands. You create encoders. 
    The encoders encode commands into the command buffer. 
    You then **finish** the encoder and it gives you the command buffer it created. 
    You can then **submit** that command buffer to have WebGPU execute the commands.

At the start of each compute pass of UpdateGrid() we will need to copy the contents of the input array, into a GPU buffer, with a `writeBuffer` command. Here's our compute pass:

{% highlight typescript %}
function updateGrid() { //to be called whenever the user clicks on the grid
    device.queue.writeBuffer(cellStateStorage[2], 0, indexArray);// write the user data into a buffer
    const encoder = device.createCommandEncoder(); // create the encoder
    /* compute pass start */
    const computePass = encoder.beginComputePass(); 

    computePass.setPipeline(computePipeline);// set the pipline layout, which refrences the bind group layout and the compute shader module
    computePass.setBindGroup(0, bindGroups[step % 2]);//this bind group will swap every render cycle
    computePass.dispatchWorkgroups(Math.ceil(gridWidth / workGroupSize), Math.ceil(gridHeight / workGroupSize));//set work groups
    computePass.end();

    /* compute pass end */

    step++; // Increment the step count

    /* RENDER PASS GOES HERE */

    const commandBuffer = encoder.finish(); // finish the encoder and get a command buffer

    device.queue.submit([commandBuffer]); // sumbit the command buffer
}

{% endhighlight %}

Note that the commands aren't executed until the command buffer is submitted. Before that final step we are only putting commands into command buffers. The device queue takes an array of command buffers, but for this simple app we only need one.

Here are all the parts of the app related to the compute shader:

{% highlight typescript linenos %}
 /* device comes from somewhere */

/* shader code */
const  computeShaderModule = device.createShaderModule({
    label: "Compute Shader",
    code: `
    @group(0) @binding(0) var<uniform> grid: vec2f;
    @group(0) @binding(1) var<storage, read> inputState: array<u32>;
    @group(0) @binding(2) var<storage> cellStateIn: array<u32>;
    @group(0) @binding(3) var<storage, read_write> cellStateOut: array<u32>;

    /* find the cell index */
    fn cellIndex(cell: vec2u) -> u32 {
        return (cell.y % u32(grid.y)) * u32(grid.x) +
               (cell.x % u32(grid.x));
      }
    
    fn cellActive(x: u32, y: u32) -> u32 {
        return cellStateIn[cellIndex(vec2(x, y))];
      }

    @compute @workgroup_size(8, 8) // a missing parameter is treated as a 1. So this is a work group of size 64 (8 X 8 X 1)
    fn computeMain(@builtin(global_invocation_id) cell: vec3u){

        let i = cellIndex(cell.xy);
        cellStateOut[i] = inputState[i] ^ cellStateIn[i];
            
    } `
})



{% endhighlight %}

Now that our egoistic wills are exhausted and our analytic minds see the nonduality of subject and object, the render pipeline and the render pass should be simple

# The Render pipeline and its shaders

You get it. The render pipeline has two shaders&mdash;the vertex shader and the fragment shader. The vertex is shader is going to draw traingles. The cells in the grid will each be made of two triangles. The fragment shader is going to color each pixel of each triangle of each cell on each goddamned grid update. The render pipeline will take a `pipeline layout` that will tell it how to feed data from the buffers through the different render stages. The `pipline layout` will include a `bindgroup layout` that will tell it how to associate attributes with buffers. Bob's your uncle you've got yourself a grid of squares.

Actually the render pipeline and the code for the vertex shader and the fragment shader should be just the same as in [Your first WebGPU app](https://codelabs.developers.google.com/your-first-webgpu-app#0). The vertex shader is declared with the `@vertex` attribute:

{% highlight rust %}
@group(0) @binding(0) var<uniform> grid: vec2f;

@vertex
fn vertexMain(@location(0) pos: vec2f,
              @builtin(instance_index) instance: u32) ->
  @builtin(position) vec4f {

  let i = f32(instance);
  let cell = vec2f(i % grid.x, floor(i / grid.x));
  let state = f32(cellState[instance]);
  let gridPos = (pos*state+1) / grid - 1 + cellOffset;

  let cellOffset = cell / grid * 2;
  let gridPos = (pos + 1) / grid - 1 + cellOffset;

  return vec4f(gridPos, 0, 1);
}
{% endhighlight %}



Drawing squares with triangles is very well covered many intros to WebGPU and WebGL. I'm going to gloss over the details. Here's our square instance:

{% highlight typescript %}
const vertices = new Float32Array([
//   (X, Y)

// triangle 1
    -1, -1,
     1, -1,
     1, 1,

// triangle 2
     -1, -1,
     1, 1,
     -1, 1,
]);
{% endhighlight %}

We're going to tell the render pipeline to pass values to the vertex shader two at time. 

Then the values in this array will be the verteces of two triangles, drawn in [clip space](https://www.w3.org/TR/webgpu/#coordinate-systems). This array, then, will form a square. [Search your feelings: you know it to be true](https://codelabs.developers.google.com/your-first-webgpu-app#3).

